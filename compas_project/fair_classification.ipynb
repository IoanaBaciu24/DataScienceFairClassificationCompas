{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### In this notebook we are going to create a classifier that respects a fairness metric. Our choice is demographic parity. \n",
    "### In order to achieve this, we are going to take a normal classificator and post process the predictions.\n",
    "### The HopefullyFairClassifier has the same fit and predict methods as a normal classifier, but it also takes information regarding the sensitive attribute. \n",
    "### We are starting with some assumptions: we have one binary sensitive attribute and binary output.\n",
    "### In the fit method, we are using a large subset of the training data in order to train the naive classifier, and a smaller subset in order to find two tresholds, one for the priviledged and the other for the unpriviledged group. The main idea of our method is to have two different treshodls, one for the priviledged and the other for the unpriviledged group. We are going to learn, on a validation set, the tresholds that together satisfy the best the demographic parity. \n",
    "### When predicting, depending on the sensitive attribute, we are going to use the appropriate treshold. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# Metrics for demographic parity\n",
    "\n",
    "\n",
    "def dp_diff(y_priv, y_unpriv):\n",
    "    \n",
    "    dp_priv = sum(y_priv)/len(y_priv)\n",
    "    dp_unpriv = sum(y_unpriv)/len(y_unpriv)\n",
    "    return dp_priv-dp_unpriv\n",
    "\n",
    "\n",
    "def disparate_impact(y_priv, y_unpriv):\n",
    "    dp_priv = sum(y_priv)/len(y_priv)\n",
    "    dp_unpriv = sum(y_unpriv)/len(y_unpriv)\n",
    "    return dp_unpriv/dp_priv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "class HopefullyFairClassifier:\n",
    "    def __init__(self, priv, unpriv, attribute) -> None:\n",
    "        self.naive_classifier = LogisticRegression(penalty=\"l2\", solver='lbfgs', C=0.01)\n",
    "        self.treshold_priv = None\n",
    "        self.treshold_unpriv = None \n",
    "        self.priv = priv \n",
    "        self.unpriv = unpriv\n",
    "        self.sensitive_attribute = attribute\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2)\n",
    "        self.naive_classifier.fit(X_train, y_train)\n",
    "\n",
    "        # now we are using the validation set to look for a treshold\n",
    "\n",
    "        mask_priv = (X_valid[:, self.sensitive_attribute] == self.priv)\n",
    "        X_priv = X_valid[mask_priv, :]\n",
    "        y_priv = y_valid[mask_priv]\n",
    "        mask_unpriv = (X_valid[:, self.sensitive_attribute] == self.unpriv)\n",
    "        X_unpriv = X_valid[mask_unpriv, :]\n",
    "        y_unpriv = y_valid[mask_unpriv]\n",
    "\n",
    "        tresholds1 = np.linspace(0.3, 0.7, 50)\n",
    "        tresholds2 = np.linspace(0.3, 0.7, 50)\n",
    "\n",
    "        min_diff = 10000\n",
    "        t_priv, t_unpriv = None, None\n",
    "        print(self.naive_classifier.predict_proba(X_priv).shape)\n",
    "\n",
    "\n",
    "        # we look for the pair of tresholds that minimizez \n",
    "        # the difference between the demographic parity of the priviledged and unpriviledged groups\n",
    "        for t1 in tresholds1:\n",
    "            for t2 in tresholds2:\n",
    "                pred_priv = np.where(self.naive_classifier.predict_proba(X_priv)[:,1] > t1, 1, 0)\n",
    "                pred_unpriv = np.where(self.naive_classifier.predict_proba(X_unpriv)[:,1] > t2, 1, 0)\n",
    "\n",
    "                diff = abs(dp_diff(pred_priv, pred_unpriv))\n",
    "                if diff < min_diff:\n",
    "                    min_diff = diff \n",
    "                    t_priv = t1\n",
    "                    t_unpriv = t2\n",
    "\n",
    "        self.treshold_priv = t_priv\n",
    "        self.treshold_unpriv = t_unpriv \n",
    "\n",
    "\n",
    "    def predict(self, X): \n",
    "        # predict using the different tresholds\n",
    "        predictions = [] \n",
    "        for x in X:\n",
    "            if x[self.sensitive_attribute] == self.priv:\n",
    "                t = self.treshold_priv\n",
    "            else:\n",
    "                t = self.treshold_unpriv \n",
    "            \n",
    "            pred = self.naive_classifier.predict_proba(np.array([x]))[:,1]\n",
    "            if pred > t:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "data = pd.read_csv('compas_processed.csv')\n",
    "y = data['not_recidivist'].to_numpy()\n",
    "X = data.drop(['not_recidivist'], axis=1).to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5278, 10)\n",
      "(5278,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.4927064 , -0.81385638, -0.14965002, -0.19056396, -0.2472656 ,\n",
       "       -0.29977561, -0.31491561, -1.15917837,  1.95338   , -0.52957189])"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "sensitive_attribute_position = 1 \n",
    "values = set(X_train[:,sensitive_attribute_position])\n",
    "priv = max(values)\n",
    "unpriv = min(values)\n",
    "\n",
    "print(priv)\n",
    "print(unpriv)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.2287180226062888\n",
      "-0.8138563784381182\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "\n",
    "classifier = HopefullyFairClassifier(priv, unpriv, sensitive_attribute_position)\n",
    "classifier.fit(X_train, y_train)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(308, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "preds = classifier.predict(X_test)\n",
    "print(preds.shape)\n",
    "print(y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1584,)\n",
      "(1584,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### When evaluating the model, our purpose is to obtain a fair model, without sacrificing too much accuracy. \n",
    "### Compared to the previous naive classifier, overall we obtained similar accuracy and precision, just slightly less compared to the previous three classifiers. However, the recall was visibly higher than any of the previous classifiers. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "def evaluate(name, y_true, y_pred):\n",
    "    print(\"For \" + name + \" classifier, we obtained: \")\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred) )\n",
    "    print(\"Precision: \", precision_score(y_true, y_pred) )\n",
    "    print(\"Recall: \", recall_score(y_true, y_pred) ) \n",
    "\n",
    "\n",
    "evaluate(\"\", y_test, preds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For  classifier, we obtained: \n",
      "Accuracy:  0.6439393939393939\n",
      "Precision:  0.6246719160104987\n",
      "Recall:  0.8409893992932862\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "mask = (X_test[:, 1] == priv)\n",
    "X_test_white = X_test[mask, :]\n",
    "y_test_white = y_test[mask]\n",
    "\n",
    "mask = (X_test[:, 1] == unpriv)\n",
    "X_test_black = X_test[mask, :]\n",
    "y_test_black = y_test[mask]\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "y_pred_black = classifier.predict(X_test_black)\n",
    "y_pred_white = classifier.predict(X_test_white)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The demographic parity is respected when the disparate impact is between 0.8 and 1.2. Perfectly fair means that our result is precisely 1. Our classifier is fair with respect to this measure. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "di = disparate_impact(y_pred_white, y_pred_black)\n",
    "di"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9744560075685904"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "evaluate('log reg black', y_test_black, y_pred_black)\n",
    "evaluate('log reg white', y_test_white, y_pred_white)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For log reg black classifier, we obtained: \n",
      "Accuracy:  0.6376811594202898\n",
      "Precision:  0.5898550724637681\n",
      "Recall:  0.8586497890295358\n",
      "For log reg white classifier, we obtained: \n",
      "Accuracy:  0.6537216828478964\n",
      "Precision:  0.6777041942604857\n",
      "Recall:  0.8186666666666667\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('testenv': venv)"
  },
  "interpreter": {
   "hash": "d1aaaaf82b4ad04f42cbb09567b16275c1dbfe02a4eb80f6ea1cc4716d2f3e8a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}