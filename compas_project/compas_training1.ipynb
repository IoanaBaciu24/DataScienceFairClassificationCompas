{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Compas First Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "def dp_diff(y_priv, y_unpriv):\n",
    "    \n",
    "    dp_priv = sum(y_priv)/len(y_priv)\n",
    "    dp_unpriv = sum(y_unpriv)/len(y_unpriv)\n",
    "    return dp_priv-dp_unpriv\n",
    "\n",
    "\n",
    "def disparate_impact(y_priv, y_unpriv):\n",
    "    dp_priv = sum(y_priv)/len(y_priv)\n",
    "    dp_unpriv = sum(y_unpriv)/len(y_unpriv)\n",
    "    return dp_unpriv/dp_priv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "DATASET = \"compas-scores-two-years.csv\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "df = pd.read_csv(DATASET)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In order to create some classifiers, the dataset had to be processed. Among the large number of columns, we chose a few, and the choice was made mostly based on what we considered essential for our study. For instance, we chose: \n",
    "1. Race, sex, age category, both sensitive attributes and important aspects of each individual\n",
    "2. Juvenile encounters with the law, we have three columns of this kind in the dataset.\n",
    "3. The number of prior offenses.\n",
    "4. The time spent in jail, in days, computed as the difference between the date of entry and release from jail.\n",
    "\n",
    "### We focused on the sensitive attributes, and the attributes that are connected to encounters with police/law. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def process_compas_binary_sensitive_attributes(df):\n",
    "\n",
    "    df = df.dropna(subset=[\"days_b_screening_arrest\", \"race\"]) # dropping missing vals\n",
    "    print(df.shape)\n",
    "\n",
    "    df = df[ (df.days_b_screening_arrest <= 30) &\n",
    "    (df.days_b_screening_arrest >= -30) &\n",
    "    (df.is_recid != -1) & (df.c_charge_degree != 'O') & (df.score_text != 'N/A') ]\n",
    "\n",
    "    df.reset_index(inplace=True, drop=True) # renumber the rows from 0 again\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "\n",
    "    relevant_attributes = ['sex',  'age_cat', 'race' ,'juv_fel_count', 'juv_misd_count', \n",
    "        'juv_other_count', 'priors_count',  'c_jail_out', 'c_jail_in', 'two_year_recid']\n",
    "\n",
    "    df_relev = df[relevant_attributes]\n",
    "    df_relev['length_of_stay'] = (pd.to_datetime(df_relev['c_jail_out']) -\n",
    "                                              pd.to_datetime(df_relev['c_jail_in'])).apply(\n",
    "                                              lambda x: x.days)\n",
    "    df_relev['sex'] = df_relev['sex'].map( {'Male':1, 'Female':0} )\n",
    "\n",
    "    df_relev['race'] = df_relev['race'].map({'Caucasian':1, 'African-American': 0, 'Asian': -1, 'Native American': -1, 'Other': -1, 'Hispanic': -1})\n",
    "\n",
    "\n",
    "    df_relev = df_relev[ (df_relev.race != -1) ]\n",
    "\n",
    "\n",
    "    df_relev = pd.concat([df_relev, pd.get_dummies(df_relev['age_cat'], prefix='age_cat')], axis=1)\n",
    "    df_relev = df_relev.drop(['age_cat', 'c_jail_out', 'c_jail_in'], axis=1)\n",
    "\n",
    "    df_relev = df_relev.dropna(subset=['race'])\n",
    "    df_relev['not_recidivist'] = 1- df_relev['two_year_recid']\n",
    "    df_relev = df_relev.drop(['two_year_recid'], axis=1)\n",
    "\n",
    "    df_relev.to_csv('compas_processed.csv', index=False)\n",
    "    print(df_relev.head())\n",
    "\n",
    "\n",
    "process_compas_binary_sensitive_attributes(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6907, 53)\n",
      "(6172, 53)\n",
      "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
      "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
      "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
      "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
      "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
      "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
      "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
      "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
      "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
      "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
      "       'decile_score.1', 'score_text', 'screening_date',\n",
      "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
      "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
      "       'start', 'end', 'event', 'two_year_recid'],\n",
      "      dtype='object')\n",
      "   sex  race  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
      "1    1     0              0               0                0             0   \n",
      "2    1     0              0               0                1             4   \n",
      "4    1     1              0               0                0            14   \n",
      "6    0     1              0               0                0             0   \n",
      "7    1     1              0               0                0             0   \n",
      "\n",
      "   length_of_stay  age_cat_25 - 45  age_cat_Greater than 45  \\\n",
      "1              10                1                        0   \n",
      "2               1                0                        0   \n",
      "4               6                1                        0   \n",
      "6               2                1                        0   \n",
      "7               1                1                        0   \n",
      "\n",
      "   age_cat_Less than 25  not_recidivist  \n",
      "1                     0               0  \n",
      "2                     1               0  \n",
      "4                     0               0  \n",
      "6                     0               1  \n",
      "7                     0               1  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_5685/1430328400.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relev['length_of_stay'] = (pd.to_datetime(df_relev['c_jail_out']) -\n",
      "/tmp/ipykernel_5685/1430328400.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relev['sex'] = df_relev['sex'].map( {'Male':1, 'Female':0} )\n",
      "/tmp/ipykernel_5685/1430328400.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relev['race'] = df_relev['race'].map({'Caucasian':1, 'African-American': 0, 'Asian': -1, 'Native American': -1, 'Other': -1, 'Hispanic': -1})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "data = pd.read_csv('compas_processed.csv')\n",
    "data.shape\n",
    "y = data['not_recidivist'].to_numpy()\n",
    "X = data.drop(['not_recidivist'], axis=1).to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5278, 10)\n",
      "(5278,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3694, 10)\n",
      "(1584, 10)\n",
      "(3694,)\n",
      "(1584,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We are training three different classifiers, and we are going to compare their results. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "logistic_regression = LogisticRegression(penalty=\"l2\", solver='lbfgs', C=0.01)\n",
    "svm = SVC(kernel='linear', C=0.1)\n",
    "mlp = MLPClassifier(hidden_layer_sizes =(12,))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "logistic_regression.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "mlp.fit(X_train, y_train)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(12,))"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "y_pred_log = logistic_regression.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_mlp = mlp.predict(X_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def evaluate(name, y_true, y_pred):\n",
    "    print(\"For \" + name + \" classifier, we obtained: \")\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred) )\n",
    "    print(\"Precision: \", precision_score(y_true, y_pred) )\n",
    "    print(\"Recall: \", recall_score(y_true, y_pred) )\n",
    "\n",
    "\n",
    "evaluate(\"logistic regression\", y_test, y_pred_log)\n",
    "evaluate(\"svm\", y_test, y_pred_svm)\n",
    "evaluate(\"mlp\", y_test, y_pred_mlp)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For logistic regression classifier, we obtained: \n",
      "Accuracy:  0.6559343434343434\n",
      "Precision:  0.6551020408163265\n",
      "Recall:  0.7561837455830389\n",
      "For svm classifier, we obtained: \n",
      "Accuracy:  0.6464646464646465\n",
      "Precision:  0.6529100529100529\n",
      "Recall:  0.7267373380447585\n",
      "For mlp classifier, we obtained: \n",
      "Accuracy:  0.6584595959595959\n",
      "Precision:  0.668859649122807\n",
      "Recall:  0.71849234393404\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "\n",
    "mask = (X_test[:, 1] > 0)\n",
    "X_test_white = X_test[mask, :]\n",
    "y_test_white = y_test[mask]\n",
    "\n",
    "mask = (X_test[:, 1] < 0)\n",
    "X_test_black = X_test[mask, :]\n",
    "y_test_black = y_test[mask]\n",
    "\n",
    "print(X_test_white.shape)\n",
    "print(X_test_black.shape)\n",
    "print(y_test_black.shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(618, 10)\n",
      "(966, 10)\n",
      "(966,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "y_pred_black = logistic_regression.predict(X_test_black)\n",
    "y_pred_white = logistic_regression.predict(X_test_white)\n",
    "\n",
    "evaluate('log reg black', y_test_black, y_pred_black)\n",
    "evaluate('log reg white', y_test_white, y_pred_white)\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "y_pred_black = svm.predict(X_test_black)\n",
    "y_pred_white = svm.predict(X_test_white)\n",
    "\n",
    "evaluate('svm black', y_test_black, y_pred_black)\n",
    "evaluate('svm white', y_test_white, y_pred_white)\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "y_pred_black = mlp.predict(X_test_black)\n",
    "y_pred_white = mlp.predict(X_test_white)\n",
    "\n",
    "evaluate('mlp black', y_test_black, y_pred_black)\n",
    "evaluate('mlp white', y_test_white, y_pred_white)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For log reg black classifier, we obtained: \n",
      "Accuracy:  0.6656314699792961\n",
      "Precision:  0.6630669546436285\n",
      "Recall:  0.6476793248945147\n",
      "For log reg white classifier, we obtained: \n",
      "Accuracy:  0.6407766990291263\n",
      "Precision:  0.6479690522243714\n",
      "Recall:  0.8933333333333333\n",
      "-----------------------------------------------\n",
      "For svm black classifier, we obtained: \n",
      "Accuracy:  0.65527950310559\n",
      "Precision:  0.6453608247422681\n",
      "Recall:  0.6603375527426161\n",
      "For svm white classifier, we obtained: \n",
      "Accuracy:  0.6326860841423948\n",
      "Precision:  0.6608695652173913\n",
      "Recall:  0.8106666666666666\n",
      "-----------------------------------------------\n",
      "For mlp black classifier, we obtained: \n",
      "Accuracy:  0.6614906832298136\n",
      "Precision:  0.6666666666666666\n",
      "Recall:  0.620253164556962\n",
      "For mlp white classifier, we obtained: \n",
      "Accuracy:  0.6537216828478964\n",
      "Precision:  0.6709129511677282\n",
      "Recall:  0.8426666666666667\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "di = disparate_impact(y_pred_white, y_pred_black)\n",
    "di"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5990030462475768"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A very naive bias mittigation strategy is to simply drop the sensitive attribute alltogether. We chose to drop race and sex. We are going to train this here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# data = pd.read_csv('compas_processed.csv')\n",
    "# data.shape\n",
    "# y = data['not_recidivist'].to_numpy()\n",
    "# X = data.drop(['not_recidivist', 'race', 'sex'], axis=1).to_numpy()\n",
    "# print(X.shape)\n",
    "# print(y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X = scaler.transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "\n",
    "# drop the race and the sex from the dataset, they are the first two columns\n",
    "X_train = np.delete(X_train, 0, 1)\n",
    "X_train = np.delete(X_train, 0, 1)\n",
    "\n",
    "\n",
    "X_test_prev = X_test\n",
    "X_test= np.delete(X_test, 0, 1)\n",
    "X_test = np.delete(X_test, 0, 1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "logistic_regression = LogisticRegression(penalty=\"l2\", solver='lbfgs', C=0.01)\n",
    "svm = SVC(kernel='linear', C=0.1)\n",
    "mlp = MLPClassifier(hidden_layer_sizes =(12,))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "logistic_regression.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "mlp.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(12,))"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "y_pred_log = logistic_regression.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_mlp = mlp.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "evaluate(\"logistic regression\", y_test, y_pred_log)\n",
    "evaluate(\"svm\", y_test, y_pred_svm)\n",
    "evaluate(\"mlp\", y_test, y_pred_mlp)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For logistic regression classifier, we obtained: \n",
      "Accuracy:  0.6565656565656566\n",
      "Precision:  0.6496565260058881\n",
      "Recall:  0.7797408716136631\n",
      "For svm classifier, we obtained: \n",
      "Accuracy:  0.6458333333333334\n",
      "Precision:  0.6518987341772152\n",
      "Recall:  0.7279151943462897\n",
      "For mlp classifier, we obtained: \n",
      "Accuracy:  0.6515151515151515\n",
      "Precision:  0.650761421319797\n",
      "Recall:  0.7550058892815077\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "mask = (X_test_prev[:, 1] > 0)\n",
    "X_test_white = X_test[mask, :]\n",
    "y_test_white = y_test[mask]\n",
    "\n",
    "mask = (X_test_prev[:, 1] < 0)\n",
    "X_test_black = X_test[mask, :]\n",
    "y_test_black = y_test[mask]\n",
    "\n",
    "print(X_test_white.shape)\n",
    "print(X_test_black.shape)\n",
    "print(y_test_black.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(618, 8)\n",
      "(966, 8)\n",
      "(966,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "y_pred_black = logistic_regression.predict(X_test_black)\n",
    "y_pred_white = logistic_regression.predict(X_test_white)\n",
    "\n",
    "evaluate('log reg black', y_test_black, y_pred_black)\n",
    "evaluate('log reg white', y_test_white, y_pred_white)\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "y_pred_black = svm.predict(X_test_black)\n",
    "y_pred_white = svm.predict(X_test_white)\n",
    "\n",
    "evaluate('svm black', y_test_black, y_pred_black)\n",
    "evaluate('svm white', y_test_white, y_pred_white)\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "y_pred_black = mlp.predict(X_test_black)\n",
    "y_pred_white = mlp.predict(X_test_white)\n",
    "\n",
    "evaluate('mlp black', y_test_black, y_pred_black)\n",
    "evaluate('mlp white', y_test_white, y_pred_white)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For log reg black classifier, we obtained: \n",
      "Accuracy:  0.6666666666666666\n",
      "Precision:  0.6407407407407407\n",
      "Recall:  0.729957805907173\n",
      "For log reg white classifier, we obtained: \n",
      "Accuracy:  0.6407766990291263\n",
      "Precision:  0.6597077244258872\n",
      "Recall:  0.8426666666666667\n",
      "-----------------------------------------------\n",
      "For svm black classifier, we obtained: \n",
      "Accuracy:  0.6563146997929606\n",
      "Precision:  0.6454918032786885\n",
      "Recall:  0.6645569620253164\n",
      "For svm white classifier, we obtained: \n",
      "Accuracy:  0.6294498381877023\n",
      "Precision:  0.658695652173913\n",
      "Recall:  0.808\n",
      "-----------------------------------------------\n",
      "For mlp black classifier, we obtained: \n",
      "Accuracy:  0.6532091097308489\n",
      "Precision:  0.6323809523809524\n",
      "Recall:  0.70042194092827\n",
      "For mlp white classifier, we obtained: \n",
      "Accuracy:  0.6488673139158576\n",
      "Precision:  0.6717391304347826\n",
      "Recall:  0.824\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "di = disparate_impact(y_pred_white, y_pred_black)\n",
    "di"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7301512287334593"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('testenv': venv)"
  },
  "interpreter": {
   "hash": "d1aaaaf82b4ad04f42cbb09567b16275c1dbfe02a4eb80f6ea1cc4716d2f3e8a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}